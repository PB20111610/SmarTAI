The paper introduces a new quantum machine learning framework called Quantum Circuit Learning (QCL). It utilizes a low-depth quantum circuit to encode input data and optimize parameters to minimize a cost function, enabling the representation of complex nonlinear functions. Theoretical analysis demonstrates that QCL can approximate any analytical function with a sufficient number of qubits. Numerical simulations showcase QCL's capability to fit nonlinear functions, perform simple classification tasks, and approximate the dynamics of a 10-spin quantum system using a 6-qubit circuit. The unitarity of quantum transformations in QCL helps prevent overfitting. This classical-quantum hybrid algorithm is feasible on near-term quantum devices and offers potential advantages over classical machine learning methods by leveraging the exponentially large Hilbert space.